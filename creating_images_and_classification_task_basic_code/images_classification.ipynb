{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:48:05.866906Z","iopub.status.busy":"2022-07-01T10:48:05.866461Z","iopub.status.idle":"2022-07-01T10:48:05.999246Z","shell.execute_reply":"2022-07-01T10:48:05.997987Z","shell.execute_reply.started":"2022-07-01T10:48:05.866876Z"},"executionInfo":{"elapsed":3899,"status":"ok","timestamp":1656002515063,"user":{"displayName":"Shirsh Mall","userId":"09973499392860875754"},"user_tz":-330},"id":"BX3ijWKqxAll","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-04-25 00:12:43.594918: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-04-25 00:12:43.885892: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-25 00:12:45.010718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-04-25 00:12:47.069277: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","import numpy as np\n","import pandas as pd\n","import os\n","from tensorflow import keras\n","from keras.preprocessing.image import ImageDataGenerator \n","from keras import Sequential\n","from keras.layers import Dense\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import BatchNormalization\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import Rescaling\n","from keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","import plotly.express as px\n","from tensorflow.nn import softmax\n","# import keras_tuner as kt\n","auc_roc_metric_ROC = tf.keras.metrics.AUC(curve='ROC')"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:07.350099Z","iopub.status.busy":"2022-07-01T10:32:07.349654Z","iopub.status.idle":"2022-07-01T10:32:07.360879Z","shell.execute_reply":"2022-07-01T10:32:07.358675Z","shell.execute_reply.started":"2022-07-01T10:32:07.350057Z"},"trusted":true},"outputs":[],"source":["# %config Completer.use_jedi = False\n","import random as python_random\n","\n","def reset_seeds():\n","   np.random.seed(10) \n","   python_random.seed(10)\n","   tf.random.set_seed(10)\n","\n","reset_seeds()"]},{"cell_type":"markdown","metadata":{},"source":["# Articles \n","***\n","# https://www.tensorflow.org/tutorials/images/classification\n","\n","https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480\n","\n","https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9\n","\n","https://www.analyticsvidhya.com/blog/2021/08/quick-start-with-tensorflow-callbacks/\n","\n","https://towardsdatascience.com/how-to-choose-the-right-activation-function-for-neural-networks-3941ff0e6f9c\n","\n","https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8\n","\n","https://medium.com/featurepreneur/data-augmentation-using-keras-preprocessing-layers-6cdc7d49328e\n","\n","https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7\n","\n","https://towardsdatascience.com/mastering-tensorflow-variables-in-5-easy-step-5ba8062a1756\n","\n","https://towardsdatascience.com/how-to-choose-the-best-keras-pre-trained-model-for-image-classification-b850ca4428d4|\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:07.365195Z","iopub.status.busy":"2022-07-01T10:32:07.364451Z","iopub.status.idle":"2022-07-01T10:32:07.381621Z","shell.execute_reply":"2022-07-01T10:32:07.380181Z","shell.execute_reply.started":"2022-07-01T10:32:07.365147Z"},"executionInfo":{"elapsed":25015,"status":"ok","timestamp":1656002540073,"user":{"displayName":"Shirsh Mall","userId":"09973499392860875754"},"user_tz":-330},"id":"xguNU1N8xPCw","outputId":"fbe173c2-4cec-42df-9883-4069d157686b","trusted":true},"outputs":[],"source":["# # To Import Data from google drive (authentication needed)\n","# from google.colab import drive \n","# drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:07.386629Z","iopub.status.busy":"2022-07-01T10:32:07.385074Z","iopub.status.idle":"2022-07-01T10:32:08.581485Z","shell.execute_reply":"2022-07-01T10:32:08.580236Z","shell.execute_reply.started":"2022-07-01T10:32:07.386586Z"},"executionInfo":{"elapsed":5630,"status":"ok","timestamp":1656002545698,"user":{"displayName":"Shirsh Mall","userId":"09973499392860875754"},"user_tz":-330},"id":"ktn8QCXYxAlt","outputId":"eaef2a81-f959-45fb-a314-9fc896cbe57d","trusted":true},"outputs":[],"source":["# Display an background image\n","from PIL import Image\n","with Image.open( '/home/abhishek/triplet_codons/images_classification_data_1st/images_classification_data_axion_classification_pT_size305/background_bb_constituents_data_images_pT/pT_0.png') as im:\n","    fig = px.imshow(im)\n","    fig.update_layout(title='An background image', width=500)\n","    fig.show()\n","    images_size = im.size\n","    print( 'Size of the Images', im.size )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:08.583177Z","iopub.status.busy":"2022-07-01T10:32:08.582709Z","iopub.status.idle":"2022-07-01T10:32:08.760914Z","shell.execute_reply":"2022-07-01T10:32:08.759793Z","shell.execute_reply.started":"2022-07-01T10:32:08.583110Z"},"trusted":true},"outputs":[],"source":["# Display an signal image\n","from PIL import Image\n","with Image.open( '/home/abhishek/triplet_codons/images_classification_data_1st/images_classification_data_axion_classification_pT_size305/signal_axion_constituents_data_images_pT/pT_0.png' ) as im:\n","    fig = px.imshow(im)\n","    fig.update_layout(width=500)\n","    fig.show()\n","    images_size = im.size\n","    print( 'Size of the Images', im.size )"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:08.763423Z","iopub.status.busy":"2022-07-01T10:32:08.762602Z","iopub.status.idle":"2022-07-01T10:32:12.908572Z","shell.execute_reply":"2022-07-01T10:32:12.907197Z","shell.execute_reply.started":"2022-07-01T10:32:08.763366Z"},"executionInfo":{"elapsed":884,"status":"ok","timestamp":1656002548860,"user":{"displayName":"Shirsh Mall","userId":"09973499392860875754"},"user_tz":-330},"id":"dcmLBkvExAlw","outputId":"b606d5f0-dd22-48d8-a133-bb519089c791","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 6000 files belonging to 2 classes.\n","Using 4800 files for training.\n","Found 6000 files belonging to 2 classes.\n","Using 1200 files for validation.\n"]}],"source":["# # Importing Dataset\n","# train = tf.keras.utils.image_dataset_from_directory( directory='/home/abhishek/triplet_codons/images_classification_data_1st/images_classification_data_axion_classification_pT_size305/',\n","#                                             shuffle=True,seed=10,color_mode='rgb',image_size=(305,305), \n","#                                             batch_size=64, validation_split=0.2,subset=\"training\" )\n","# val = tf.keras.utils.image_dataset_from_directory( directory='/home/abhishek/triplet_codons/images_classification_data_1st/images_classification_data_axion_classification_pT_size305/',\n","#                                             shuffle=True,seed=10,color_mode='rgb',image_size=(305,305),\n","#                                             batch_size=64, validation_split=0.2,subset=\"validation\" )\n","\n","train = tf.keras.utils.image_dataset_from_directory( directory='/home/abhishek/Desktop/deltaeta_invmass_images_classification/images_norep_nocuts/',\n","                                            shuffle=True,seed=10,color_mode='grayscale',image_size=(2921,2921), \n","                                            batch_size=64, validation_split=0.2,subset=\"training\" )\n","val = tf.keras.utils.image_dataset_from_directory( directory='/home/abhishek/Desktop/deltaeta_invmass_images_classification/images_norep_nocuts/',\n","                                            shuffle=True,seed=10,color_mode='grayscale',image_size=(2921,2921),\n","                                            batch_size=64, validation_split=0.2,subset=\"validation\" )\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:15.970991Z","iopub.status.busy":"2022-07-01T10:32:15.968607Z","iopub.status.idle":"2022-07-01T10:32:15.983132Z","shell.execute_reply":"2022-07-01T10:32:15.981649Z","shell.execute_reply.started":"2022-07-01T10:32:15.970918Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['background', 'signal']"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["class_names = train.class_names\n","no_of_classes = len( class_names )\n","class_names"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:15.985563Z","iopub.status.busy":"2022-07-01T10:32:15.984928Z","iopub.status.idle":"2022-07-01T10:32:16.001766Z","shell.execute_reply":"2022-07-01T10:32:16.000238Z","shell.execute_reply.started":"2022-07-01T10:32:15.985535Z"},"trusted":true},"outputs":[],"source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train = train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val = val.cache().prefetch(buffer_size=AUTOTUNE)"]},{"cell_type":"markdown","metadata":{},"source":["## Notation:\n"," * **24C5** --> convolution layer (24 feature, 5x5 filter and stride 1)\n"," * **24C5S2** --> convolution layer (24 feature, 5x5 filter and stride 2)\n"," * **MP2S2** --> max pooling (2x2 filter and stride 2) ( Default (2,2))\n"," * **256D** --> fully connected dense layer (256 units) \n"," "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 1: Estimate Number of Convolution Layers required\n","* 1)  256*256*3-50C3MP2-F-150D-4D-Compile\n","* 2)  256*256*3-50C3MP2-30C3MP2-F-150D-4D-Compile\n","* 3)  256*256*3-50C3MP2-30C3MP2-20C3MP2-F-150D-4D-Compile\n","* 4)  256*256*3-50C3MP2-40C3MP2-30C3MP2-20C3MP2-F-150D-4D-Compile"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:17.597675Z","iopub.status.busy":"2022-07-01T10:32:17.596876Z","iopub.status.idle":"2022-07-01T10:32:17.603429Z","shell.execute_reply":"2022-07-01T10:32:17.602039Z","shell.execute_reply.started":"2022-07-01T10:32:17.597632Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 2921, 2921, 5)     50        \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 1460, 1460, 5)    0         \n"," )                                                               \n","                                                                 \n"," flatten (Flatten)           (None, 10658000)          0         \n","                                                                 \n"," dense (Dense)               (None, 256)               2728448256\n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 2,728,448,563\n","Trainable params: 2,728,448,563\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model_1 = Sequential()\n","model_1.add( Conv2D( filters=5 ,kernel_size=3, padding='same', activation='relu', input_shape=(2921,2921,1) ) )\n","model_1.add( MaxPooling2D() ) \n","\n","model_1.add( Flatten() )\n","model_1.add( Dense(units=256,activation='relu') )\n","model_1.add( Dense(units=1, activation='sigmoid') )\n","model_1.compile( optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=['accuracy',auc_roc_metric_ROC] )\n","model_1.summary()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:17.605942Z","iopub.status.busy":"2022-07-01T10:32:17.605136Z","iopub.status.idle":"2022-07-01T10:32:17.618294Z","shell.execute_reply":"2022-07-01T10:32:17.616950Z","shell.execute_reply.started":"2022-07-01T10:32:17.605899Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-04-25 00:15:24.240824: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [4800]\n","\t [[{{node Placeholder/_0}}]]\n","2023-04-25 00:15:24.241185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [4800]\n","\t [[{{node Placeholder/_4}}]]\n","2023-04-25 00:15:36.933724: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 7 of 1000\n","2023-04-25 00:15:47.688897: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 23 of 1000\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mCanceled future for execute_request message before replies were done"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["model_1.fit( train, validation_data=val, epochs=5 )"]},{"cell_type":"markdown","metadata":{},"source":["## Step 8: Add Data Augmentation"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-06-26T20:28:28.235476Z","iopub.status.busy":"2022-06-26T20:28:28.235019Z","iopub.status.idle":"2022-06-26T20:28:28.240024Z","shell.execute_reply":"2022-06-26T20:28:28.238826Z","shell.execute_reply.started":"2022-06-26T20:28:28.235436Z"}},"source":["## Step 9: Adding Callback"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:18.721504Z","iopub.status.busy":"2022-07-01T10:32:18.720604Z","iopub.status.idle":"2022-07-01T10:32:19.113296Z","shell.execute_reply":"2022-07-01T10:32:19.111084Z","shell.execute_reply.started":"2022-07-01T10:32:18.721462Z"},"trusted":true},"outputs":[],"source":["model = Sequential()\n","model.add( layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\", input_shape=(305,305,3)))\n","model.add( layers.experimental.preprocessing.RandomRotation(0.2) )\n","# model.add( layers.experimental.preprocessing.RandomCrop(width=230,height=230) )\n","model.add( layers.experimental.preprocessing.RandomZoom(0.2) )\n","model.add( Conv2D( filters=8, kernel_size=3, padding='same', activation='relu') )\n","model.add( BatchNormalization() )\n","model.add( MaxPooling2D() )\n","            \n","model.add( Conv2D( filters=16, kernel_size=3, padding='same', activation='relu' ) )\n","model.add( BatchNormalization() )\n","model.add( MaxPooling2D() )\n","model.add( Dropout(0.1))\n","            \n","model.add( Conv2D( filters=32, kernel_size=3, padding='same', activation='relu' ) )\n","model.add( BatchNormalization() )\n","model.add( MaxPooling2D() )\n","model.add( Dropout(0.1))\n","\n","model.add( Flatten() )\n","model.add( Dense(units=64,activation='relu') )\n","model.add( BatchNormalization() )\n","model.add( Dropout(0.2))\n","model.add( Dense(units=1, activation='sigmoid') )\n","model.compile( optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',auc_roc_metric_ROC])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:32:19.115587Z","iopub.status.busy":"2022-07-01T10:32:19.114995Z","iopub.status.idle":"2022-07-01T10:33:24.298579Z","shell.execute_reply":"2022-07-01T10:33:24.297244Z","shell.execute_reply.started":"2022-07-01T10:32:19.115543Z"},"trusted":true},"outputs":[],"source":["callback = EarlyStopping(monitor='loss', patience=2)\n","history = model.fit( train, validation_data=val, epochs=20, callbacks=[callback])"]},{"cell_type":"markdown","metadata":{},"source":["## Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:33:24.301090Z","iopub.status.busy":"2022-07-01T10:33:24.300360Z","iopub.status.idle":"2022-07-01T10:33:24.314338Z","shell.execute_reply":"2022-07-01T10:33:24.312679Z","shell.execute_reply.started":"2022-07-01T10:33:24.301042Z"},"trusted":true},"outputs":[],"source":["accuracy = history.history['accuracy']\n","val_accuracy = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = np.linspace(1,15,15)\n","epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:33:24.317075Z","iopub.status.busy":"2022-07-01T10:33:24.316535Z","iopub.status.idle":"2022-07-01T10:33:24.340509Z","shell.execute_reply":"2022-07-01T10:33:24.339182Z","shell.execute_reply.started":"2022-07-01T10:33:24.317001Z"},"trusted":true},"outputs":[],"source":["fig = go.Figure(data=go.Scatter( x=epochs, y=loss, name='loss' ))\n","fig.add_trace( go.Scatter( x=epochs, y=val_loss, name='val_loss' ) )\n","fig.update_layout( title=\"Loss\", xaxis_title='epochs' )\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:41:55.795345Z","iopub.status.busy":"2022-07-01T10:41:55.794729Z","iopub.status.idle":"2022-07-01T10:41:55.817682Z","shell.execute_reply":"2022-07-01T10:41:55.816406Z","shell.execute_reply.started":"2022-07-01T10:41:55.795297Z"},"trusted":true},"outputs":[],"source":["fig = go.Figure(data=go.Scatter(x=epochs, y=accuracy, name='accuracy' ))\n","fig.add_trace( go.Scatter( x=epochs, y=val_accuracy, name='val_accuracy' ) )\n","fig.update_layout( title=\"Accuracy\",xaxis_title='epochs' )\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:41:56.108425Z","iopub.status.busy":"2022-07-01T10:41:56.107708Z","iopub.status.idle":"2022-07-01T10:41:58.567720Z","shell.execute_reply":"2022-07-01T10:41:58.566324Z","shell.execute_reply.started":"2022-07-01T10:41:56.108369Z"},"trusted":true},"outputs":[],"source":["predictions_test = model.predict(val)\n","\n","for images,labels in val.take(1):\n","    for i in range(10):\n","        score = softmax( predictions_test[i] )\n","        fig = px.imshow( images[i] )\n","        fig.update_layout(width=500,title=class_names[labels[i]])\n","        fig.show()\n","        print( 'Actaul Class: ', class_names[labels[i]] )\n","        print('Predicted Class: {} with Percent Confidence:{}'.format(class_names[np.argmax(score)], 100 * np.max(score)))\n","        if class_names[labels[i]] != class_names[np.argmax(score)] :\n","            print(\"Incorrect Prediction\")\n","        else:\n","            print('Correct Prediction')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:41:58.571528Z","iopub.status.busy":"2022-07-01T10:41:58.570387Z","iopub.status.idle":"2022-07-01T10:41:59.308831Z","shell.execute_reply":"2022-07-01T10:41:59.307359Z","shell.execute_reply.started":"2022-07-01T10:41:58.571482Z"},"trusted":true},"outputs":[],"source":["# predictions_val = model.predict(val)\n","\n","# for images,labels in val.take(1):\n","#     for i in range(10):\n","#         score = softmax( predictions_val[i] )\n","#         fig = px.imshow( images[i] )\n","#         fig.update_layout(width=500,title=class_names[labels[i]])\n","#         fig.show()\n","#         print( 'Actaul Class: ', class_names[labels[i]] )\n","#         print('Predicted Class: {} with Percent Confidence:{}'.format(class_names[np.argmax(score)], 100 * np.max(score)))\n","#         if class_names[labels[i]] != class_names[np.argmax(score)] :\n","#             print(\"Incorrect Prediction\")\n","#         else:\n","#             print('Correct Prediction')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:41:59.311845Z","iopub.status.busy":"2022-07-01T10:41:59.311407Z","iopub.status.idle":"2022-07-01T10:42:04.894975Z","shell.execute_reply":"2022-07-01T10:42:04.893645Z","shell.execute_reply.started":"2022-07-01T10:41:59.311804Z"},"trusted":true},"outputs":[],"source":["# model.save('./Step_By_Step_Method_Model')"]},{"cell_type":"markdown","metadata":{},"source":["***\n","***\n","***"]},{"cell_type":"markdown","metadata":{},"source":["## Creating Some Useful Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:42:04.905377Z","iopub.status.busy":"2022-07-01T10:42:04.904587Z","iopub.status.idle":"2022-07-01T10:42:04.916637Z","shell.execute_reply":"2022-07-01T10:42:04.915149Z","shell.execute_reply.started":"2022-07-01T10:42:04.905332Z"},"trusted":true},"outputs":[],"source":["# Plotting Loss vs epochs graph, Accuaracy vs epochs graph\n","def Plot_Loss_Accuracy( history ):\n","    accuracy = history.history['accuracy']\n","    val_accuracy = history.history['val_accuracy']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","\n","    epochs = np.linspace(1,15,15)\n","    epochs\n","\n","\n","    fig = go.Figure(data=go.Scatter( x=epochs, y=loss, name='loss' ))\n","    fig.add_trace( go.Scatter( x=epochs, y=val_loss, name='val_loss' ) )\n","    fig.update_layout( title=\"Loss\", xaxis_title='epochs' )\n","    fig.show()\n","\n","\n","    fig = go.Figure(data=go.Scatter(x=epochs, y=accuracy, name='accuracy' ))\n","    fig.add_trace( go.Scatter( x=epochs, y=val_accuracy, name='val_accuracy' ) )\n","    fig.update_layout( title=\"Accuracy\",xaxis_title='epochs' )\n","    fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T10:42:04.919322Z","iopub.status.busy":"2022-07-01T10:42:04.918718Z","iopub.status.idle":"2022-07-01T10:42:04.937256Z","shell.execute_reply":"2022-07-01T10:42:04.935716Z","shell.execute_reply.started":"2022-07-01T10:42:04.919281Z"},"trusted":true},"outputs":[],"source":["# Displaying Images in Validation/Test Set, Model Predictions and Confidence Level\n","def Prediction_Results( model, data, no_of_images):\n","    predictions = model.predict(data)\n","\n","    for images,labels in data.take(1):\n","        for i in range(no_of_images):\n","            score = softmax( predictions[i] )\n","            fig = px.imshow( images[i] )\n","            fig.update_layout(width=500,title=class_names[labels[i]])\n","            fig.show()\n","            print( 'Actaul Class: ', class_names[labels[i]] )\n","            print('Predicted Class: {} with Percent Confidence:{}'.format(class_names[np.argmax(score)], 100 * np.max(score)))\n","            if class_names[labels[i]] == class_names[np.argmax(score)] :\n","                print(\"Correct Prediction\")\n","            else:\n","                print('Incorrect Prediction')"]},{"cell_type":"markdown","metadata":{},"source":["***\n","***"]},{"cell_type":"markdown","metadata":{},"source":["***\n","***"]},{"cell_type":"markdown","metadata":{},"source":["# Transfer Learning"]},{"cell_type":"markdown","metadata":{},"source":["## Trasnfer Learning using ResNet50"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T11:01:07.358011Z","iopub.status.busy":"2022-07-01T11:01:07.357269Z","iopub.status.idle":"2022-07-01T11:01:07.371041Z","shell.execute_reply":"2022-07-01T11:01:07.369277Z","shell.execute_reply.started":"2022-07-01T11:01:07.357969Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","import numpy as np\n","import pandas as pd\n","import os\n","from tensorflow import keras\n","from keras.preprocessing.image import ImageDataGenerator \n","from keras import Sequential\n","from keras.layers import Dense\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import BatchNormalization\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import Rescaling\n","from keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","import plotly.express as px\n","from tensorflow.nn import softmax\n","# load_img(r'C:\\Users\\shirs\\Desktop\\Image Classification\\Cotton Disease Prediction Project-Youtube Krish Naik\\train\\fresh cotton leaf\\d (88)_iaip.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T11:01:07.373392Z","iopub.status.busy":"2022-07-01T11:01:07.372720Z","iopub.status.idle":"2022-07-01T11:01:12.806188Z","shell.execute_reply":"2022-07-01T11:01:12.804557Z","shell.execute_reply.started":"2022-07-01T11:01:07.373337Z"},"trusted":true},"outputs":[],"source":["model_ResNet50 = Sequential()\n","model_ResNet50.add( layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\", input_shape=(256,256,3)))\n","model_ResNet50.add( layers.experimental.preprocessing.RandomRotation(0.2) )\n","# model_ResNet50.add( layers.experimental.preprocessing.RandomCrop(width=230,height=230) )\n","model_ResNet50.add( layers.experimental.preprocessing.RandomZoom(0.2) )\n","model_ResNet50.add( layers.RandomContrast(0.2) )\n","pretrained_model = tf.keras.applications.ResNet50( include_top=False,classes=2,weights='imagenet' )\n","pretrained_model.trainable = False\n","model_ResNet50.add( pretrained_model )\n","model_ResNet50.add( Flatten() )\n","model_ResNet50.add( Dense( units=256, activation='relu'))\n","model_ResNet50.add( BatchNormalization() )\n","# model_ResNet50.add( Dropout(0.1) )\n","model_ResNet50.add( Dense( units=256, activation='relu'))\n","model_ResNet50.add( Dense( units=1, activation='sigmoid' ) )\n","model_ResNet50.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T11:01:12.813084Z","iopub.status.busy":"2022-07-01T11:01:12.812703Z","iopub.status.idle":"2022-07-01T11:02:34.877195Z","shell.execute_reply":"2022-07-01T11:02:34.875927Z","shell.execute_reply.started":"2022-07-01T11:01:12.813054Z"},"trusted":true},"outputs":[],"source":["model_ResNet50.compile( optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',auc_roc_metric_ROC])\n","history = model_ResNet50.fit( train, validation_data=val, epochs=20 )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T11:02:34.879973Z","iopub.status.busy":"2022-07-01T11:02:34.879497Z","iopub.status.idle":"2022-07-01T11:03:16.035035Z","shell.execute_reply":"2022-07-01T11:03:16.033620Z","shell.execute_reply.started":"2022-07-01T11:02:34.879921Z"},"trusted":true},"outputs":[],"source":["model_ResNet50.save('./TransferLearning_ResNet50_Model')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T11:03:16.046352Z","iopub.status.busy":"2022-07-01T11:03:16.045979Z","iopub.status.idle":"2022-07-01T11:03:16.076455Z","shell.execute_reply":"2022-07-01T11:03:16.075296Z","shell.execute_reply.started":"2022-07-01T11:03:16.046323Z"},"trusted":true},"outputs":[],"source":["Plot_Loss_Accuracy( history=history )"]},{"cell_type":"markdown","metadata":{},"source":["## Transfer Learning using VGG16 Network"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T11:08:23.095154Z","iopub.status.busy":"2022-07-01T11:08:23.093674Z","iopub.status.idle":"2022-07-01T11:08:26.819923Z","shell.execute_reply":"2022-07-01T11:08:26.818304Z","shell.execute_reply.started":"2022-07-01T11:08:23.095095Z"},"trusted":true},"outputs":[],"source":["model_VGG16 = Sequential()\n","pretrained_model = tf.keras.applications.VGG16(include_top=False, classes=2, weights='imagenet' )\n","pretrained_model.trainable = False\n","model_VGG16.add( layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\", input_shape=(305,305,3)))\n","model_VGG16.add( layers.experimental.preprocessing.RandomRotation(0.2) )\n","#model_VGG16.add( layers.experimental.preprocessing.RandomCrop(width=230,height=230) )\n","model_VGG16.add( layers.experimental.preprocessing.RandomZoom(0.2) )\n","model_VGG16.add( layers.RandomContrast(0.2) )\n","model_VGG16.add( pretrained_model )\n","model_VGG16.add( Flatten() )\n","model_VGG16.add( Dense( units=512, activation='relu'))\n","model_VGG16.add( BatchNormalization())\n","model_VGG16.add( Dense( units=256, activation='relu'))\n","model_VGG16.add( Dense( units=1, activation='sigmoid' ) )\n","model_VGG16.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T11:08:26.822524Z","iopub.status.busy":"2022-07-01T11:08:26.821972Z","iopub.status.idle":"2022-07-01T11:11:23.479845Z","shell.execute_reply":"2022-07-01T11:11:23.478560Z","shell.execute_reply.started":"2022-07-01T11:08:26.822474Z"},"trusted":true},"outputs":[],"source":["model_VGG16.compile( optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',auc_roc_metric_ROC])\n","history = model_VGG16.fit( train, validation_data=val, epochs=20 )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T11:11:23.481808Z","iopub.status.busy":"2022-07-01T11:11:23.481471Z","iopub.status.idle":"2022-07-01T11:11:30.625458Z","shell.execute_reply":"2022-07-01T11:11:30.624219Z","shell.execute_reply.started":"2022-07-01T11:11:23.481780Z"},"trusted":true},"outputs":[],"source":["model_VGG16.save('./TransferLearning_VGG16_Model')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T11:11:30.628369Z","iopub.status.busy":"2022-07-01T11:11:30.627905Z","iopub.status.idle":"2022-07-01T11:11:30.656745Z","shell.execute_reply":"2022-07-01T11:11:30.655413Z","shell.execute_reply.started":"2022-07-01T11:11:30.628327Z"},"trusted":true},"outputs":[],"source":["Plot_Loss_Accuracy( history=history )"]},{"cell_type":"markdown","metadata":{},"source":["### Best Validation Accuracy is provided by ResNet50 Model\n","### Train Accuracy of VGG16 Model is also good but it takes very long time to complete the training ( 10 minutes per epochs )\n"]},{"cell_type":"markdown","metadata":{},"source":["***\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T11:11:32.890271Z","iopub.status.busy":"2022-07-01T11:11:32.889458Z","iopub.status.idle":"2022-07-01T11:11:48.786219Z","shell.execute_reply":"2022-07-01T11:11:48.784922Z","shell.execute_reply.started":"2022-07-01T11:11:32.890195Z"},"trusted":true},"outputs":[],"source":["final_model = tf.keras.models.load_model('./TransferLearning_ResNet50_Model' )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
